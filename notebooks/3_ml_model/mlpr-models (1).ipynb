{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-27T05:58:57.726359Z",
     "iopub.status.busy": "2025-04-27T05:58:57.725642Z",
     "iopub.status.idle": "2025-04-27T05:59:05.572623Z",
     "shell.execute_reply": "2025-04-27T05:59:05.571868Z",
     "shell.execute_reply.started": "2025-04-27T05:58:57.726336Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "storm_df = pd.read_csv(\"/kaggle/input/noaa-powout-prism-0-1-is-storm-lag/noaapowoutprism_01_Is_Storm_Lag (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:05.574126Z",
     "iopub.status.busy": "2025-04-27T05:59:05.573893Z",
     "iopub.status.idle": "2025-04-27T05:59:05.743755Z",
     "shell.execute_reply": "2025-04-27T05:59:05.742943Z",
     "shell.execute_reply.started": "2025-04-27T05:59:05.574102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define features\n",
    "storm_features = [\n",
    "    'DEATHS_INDIRECT', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
    "    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'customers_out', 'duration_hours',\n",
    "    'desc_word_count', 'desc_char_count',\n",
    "    'has_tornado', 'has_hail', 'has_flood', 'has_wind', 'has_tree',\n",
    "    'has_power', 'has_damage', 'has_outage', 'has_broken', 'has_blown',\n",
    "    'tmin', 'tmax', 'tavg', 'ppt'\n",
    "]\n",
    "\n",
    "# Prepare X and y\n",
    "X = storm_df[storm_features]\n",
    "y = storm_df['is_storm_lagged'].astype(int)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Model: Random Forest for classification whether a storm is occurs in the next hour or not\n",
    "\n",
    "We use the Lag model approach to predict the whether a storm will occur in the next hour based on the given features. After testing a few models, we choose the Random Forest model for its  performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:05.744802Z",
     "iopub.status.busy": "2025-04-27T05:59:05.744565Z",
     "iopub.status.idle": "2025-04-27T05:59:21.101794Z",
     "shell.execute_reply": "2025-04-27T05:59:21.101192Z",
     "shell.execute_reply.started": "2025-04-27T05:59:05.744779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train Random Forest model on all data\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_scaled, y)\n",
    "\n",
    "# Predict on all data\n",
    "predictions = rf_model.predict(X_scaled)\n",
    "\n",
    "# Create new DataFrame with predictions\n",
    "storm_df_with_predictions = storm_df.copy()\n",
    "storm_df_with_predictions['predicted_storm'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:21.103394Z",
     "iopub.status.busy": "2025-04-27T05:59:21.103175Z",
     "iopub.status.idle": "2025-04-27T05:59:21.188883Z",
     "shell.execute_reply": "2025-04-27T05:59:21.188087Z",
     "shell.execute_reply.started": "2025-04-27T05:59:21.103377Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "storm_df_with_1_predictions = storm_df_with_predictions[storm_df_with_predictions['predicted_storm'] == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:21.189945Z",
     "iopub.status.busy": "2025-04-27T05:59:21.189721Z",
     "iopub.status.idle": "2025-04-27T05:59:21.252781Z",
     "shell.execute_reply": "2025-04-27T05:59:21.251943Z",
     "shell.execute_reply.started": "2025-04-27T05:59:21.189929Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>customers_out</th>\n",
       "      <th>power_outage_datetime</th>\n",
       "      <th>storm_start_datetime_est</th>\n",
       "      <th>storm_end_datetime_est</th>\n",
       "      <th>duration_hours</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>CZ_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>has_flood</th>\n",
       "      <th>has_wind</th>\n",
       "      <th>has_tree</th>\n",
       "      <th>has_power</th>\n",
       "      <th>has_damage</th>\n",
       "      <th>has_outage</th>\n",
       "      <th>has_broken</th>\n",
       "      <th>has_blown</th>\n",
       "      <th>is_storm_lagged</th>\n",
       "      <th>predicted_storm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-15 05:00:00</td>\n",
       "      <td>2015-01-15 05:00:00</td>\n",
       "      <td>2015-01-15 10:00:00</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Winter Weather</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-15 05:15:00</td>\n",
       "      <td>2015-01-15 05:00:00</td>\n",
       "      <td>2015-01-15 10:00:00</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Winter Weather</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-15 05:30:00</td>\n",
       "      <td>2015-01-15 05:30:00</td>\n",
       "      <td>2015-01-15 10:00:00</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Winter Weather</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-15 05:45:00</td>\n",
       "      <td>2015-01-15 05:30:00</td>\n",
       "      <td>2015-01-15 10:00:00</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Winter Weather</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-15 06:00:00</td>\n",
       "      <td>2015-01-15 06:00:00</td>\n",
       "      <td>2015-01-15 10:30:00</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Winter Weather</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210264</th>\n",
       "      <td>395247</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023-12-25 20:00:00</td>\n",
       "      <td>2023-12-25 20:00:00</td>\n",
       "      <td>2023-12-26 00:46:00</td>\n",
       "      <td>4.766667</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56.0</td>\n",
       "      <td>High Wind</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210265</th>\n",
       "      <td>395248</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2023-12-25 20:15:00</td>\n",
       "      <td>2023-12-25 20:00:00</td>\n",
       "      <td>2023-12-26 00:46:00</td>\n",
       "      <td>4.766667</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56.0</td>\n",
       "      <td>High Wind</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210269</th>\n",
       "      <td>395252</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2023-12-25 21:30:00</td>\n",
       "      <td>2023-12-25 21:30:00</td>\n",
       "      <td>2023-12-26 16:45:00</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Heavy Snow</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210270</th>\n",
       "      <td>395253</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2023-12-25 21:45:00</td>\n",
       "      <td>2023-12-25 21:36:00</td>\n",
       "      <td>2023-12-26 02:02:00</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Blizzard</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210271</th>\n",
       "      <td>395254</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2023-12-25 22:00:00</td>\n",
       "      <td>2023-12-25 21:36:00</td>\n",
       "      <td>2023-12-26 02:02:00</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Blizzard</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106379 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  customers_out power_outage_datetime  \\\n",
       "4               25            1.0   2015-01-15 05:00:00   \n",
       "5               26            1.0   2015-01-15 05:15:00   \n",
       "6               27            1.0   2015-01-15 05:30:00   \n",
       "7               28            1.0   2015-01-15 05:45:00   \n",
       "8               29            1.0   2015-01-15 06:00:00   \n",
       "...            ...            ...                   ...   \n",
       "210264      395247            5.0   2023-12-25 20:00:00   \n",
       "210265      395248            4.0   2023-12-25 20:15:00   \n",
       "210269      395252            3.0   2023-12-25 21:30:00   \n",
       "210270      395253            3.0   2023-12-25 21:45:00   \n",
       "210271      395254            3.0   2023-12-25 22:00:00   \n",
       "\n",
       "       storm_start_datetime_est storm_end_datetime_est  duration_hours  \\\n",
       "4           2015-01-15 05:00:00    2015-01-15 10:00:00        5.000000   \n",
       "5           2015-01-15 05:00:00    2015-01-15 10:00:00        5.000000   \n",
       "6           2015-01-15 05:30:00    2015-01-15 10:00:00        4.500000   \n",
       "7           2015-01-15 05:30:00    2015-01-15 10:00:00        4.500000   \n",
       "8           2015-01-15 06:00:00    2015-01-15 10:30:00        4.500000   \n",
       "...                         ...                    ...             ...   \n",
       "210264      2023-12-25 20:00:00    2023-12-26 00:46:00        4.766667   \n",
       "210265      2023-12-25 20:00:00    2023-12-26 00:46:00        4.766667   \n",
       "210269      2023-12-25 21:30:00    2023-12-26 16:45:00       19.250000   \n",
       "210270      2023-12-25 21:36:00    2023-12-26 02:02:00        4.433333   \n",
       "210271      2023-12-25 21:36:00    2023-12-26 02:02:00        4.433333   \n",
       "\n",
       "          STATE  STATE_FIPS      EVENT_TYPE CZ_TYPE  ...  has_flood has_wind  \\\n",
       "4       ALABAMA         1.0  Winter Weather       Z  ...          0        0   \n",
       "5       ALABAMA         1.0  Winter Weather       Z  ...          0        0   \n",
       "6       ALABAMA         1.0  Winter Weather       Z  ...          0        0   \n",
       "7       ALABAMA         1.0  Winter Weather       Z  ...          0        0   \n",
       "8       ALABAMA         1.0  Winter Weather       Z  ...          0        0   \n",
       "...         ...         ...             ...     ...  ...        ...      ...   \n",
       "210264  WYOMING        56.0       High Wind       Z  ...          0        1   \n",
       "210265  WYOMING        56.0       High Wind       Z  ...          0        1   \n",
       "210269  WYOMING        56.0      Heavy Snow       Z  ...          0        1   \n",
       "210270  WYOMING        56.0        Blizzard       Z  ...          0        1   \n",
       "210271  WYOMING        56.0        Blizzard       Z  ...          0        1   \n",
       "\n",
       "       has_tree  has_power  has_damage  has_outage  has_broken  has_blown  \\\n",
       "4             0          0           0           0           0          0   \n",
       "5             0          0           0           0           0          0   \n",
       "6             0          0           0           0           0          0   \n",
       "7             0          0           0           0           0          0   \n",
       "8             0          0           0           0           0          0   \n",
       "...         ...        ...         ...         ...         ...        ...   \n",
       "210264        0          0           0           0           0          0   \n",
       "210265        0          0           0           0           0          0   \n",
       "210269        0          0           0           0           0          0   \n",
       "210270        0          0           0           0           0          0   \n",
       "210271        0          0           0           0           0          0   \n",
       "\n",
       "        is_storm_lagged predicted_storm  \n",
       "4                     1               1  \n",
       "5                     1               1  \n",
       "6                     1               1  \n",
       "7                     1               1  \n",
       "8                     1               1  \n",
       "...                 ...             ...  \n",
       "210264                1               1  \n",
       "210265                1               1  \n",
       "210269                1               1  \n",
       "210270                1               1  \n",
       "210271                1               1  \n",
       "\n",
       "[106379 rows x 48 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storm_df_with_1_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Model: Random Forest for predicting severity of a storm if it occurs in the next hour\n",
    "\n",
    "After Feature Selection, we selected the most relevant features for severity prediction after which we tested a few Classification Models after which the Random Forest model gave the best Performance (92% acc) to predict the severity of a storm if it occurs in the next hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:21.253781Z",
     "iopub.status.busy": "2025-04-27T05:59:21.253552Z",
     "iopub.status.idle": "2025-04-27T05:59:21.308696Z",
     "shell.execute_reply": "2025-04-27T05:59:21.307818Z",
     "shell.execute_reply.started": "2025-04-27T05:59:21.253766Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "severity_features = [\n",
    "    # Original impact features\n",
    "    'DEATHS_INDIRECT', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
    "    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'customers_out', 'duration_hours',\n",
    "\n",
    "    # NLP-derived features\n",
    "    'desc_word_count', 'desc_char_count',\n",
    "    'has_tornado', 'has_hail', 'has_flood', 'has_wind', 'has_tree',\n",
    "    'has_power', 'has_damage', 'has_outage', 'has_broken', 'has_blown',\n",
    "\n",
    "    #prism features\n",
    "    'tmin', 'tmax', 'tavg', 'ppt'\n",
    "]\n",
    "\n",
    "X = storm_df_with_1_predictions[severity_features]\n",
    "y = storm_df_with_1_predictions['severity_class']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:21.309842Z",
     "iopub.status.busy": "2025-04-27T05:59:21.309567Z",
     "iopub.status.idle": "2025-04-27T05:59:41.252198Z",
     "shell.execute_reply": "2025-04-27T05:59:41.251507Z",
     "shell.execute_reply.started": "2025-04-27T05:59:21.309816Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train Random Forest model on all data\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_scaled, y)\n",
    "\n",
    "# Predict on all data\n",
    "predictions = rf_model.predict(X_scaled)\n",
    "\n",
    "# Create new DataFrame with predictions\n",
    "storm_data_with_severity = storm_df_with_1_predictions.copy()\n",
    "storm_data_with_severity['severity_predicted'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:41.253232Z",
     "iopub.status.busy": "2025-04-27T05:59:41.253000Z",
     "iopub.status.idle": "2025-04-27T05:59:41.307738Z",
     "shell.execute_reply": "2025-04-27T05:59:41.307128Z",
     "shell.execute_reply.started": "2025-04-27T05:59:41.253215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create three DataFrames based on predicted severity\n",
    "df_low = storm_data_with_severity[storm_data_with_severity['severity_predicted'] == 0]\n",
    "df_medium = storm_data_with_severity[storm_data_with_severity['severity_predicted'] == 1]\n",
    "df_high = storm_data_with_severity[storm_data_with_severity['severity_predicted'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:41.308672Z",
     "iopub.status.busy": "2025-04-27T05:59:41.308438Z",
     "iopub.status.idle": "2025-04-27T05:59:41.345253Z",
     "shell.execute_reply": "2025-04-27T05:59:41.344588Z",
     "shell.execute_reply.started": "2025-04-27T05:59:41.308634Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>customers_out</th>\n",
       "      <th>power_outage_datetime</th>\n",
       "      <th>storm_start_datetime_est</th>\n",
       "      <th>storm_end_datetime_est</th>\n",
       "      <th>duration_hours</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>CZ_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>has_wind</th>\n",
       "      <th>has_tree</th>\n",
       "      <th>has_power</th>\n",
       "      <th>has_damage</th>\n",
       "      <th>has_outage</th>\n",
       "      <th>has_broken</th>\n",
       "      <th>has_blown</th>\n",
       "      <th>is_storm_lagged</th>\n",
       "      <th>predicted_storm</th>\n",
       "      <th>severity_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-15 05:30:00</td>\n",
       "      <td>2015-01-15 05:30:00</td>\n",
       "      <td>2015-01-15 10:00:00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Winter Weather</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-15 05:45:00</td>\n",
       "      <td>2015-01-15 05:30:00</td>\n",
       "      <td>2015-01-15 10:00:00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Winter Weather</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-15 06:00:00</td>\n",
       "      <td>2015-01-15 06:00:00</td>\n",
       "      <td>2015-01-15 10:30:00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Winter Weather</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-15 06:15:00</td>\n",
       "      <td>2015-01-15 06:00:00</td>\n",
       "      <td>2015-01-15 10:30:00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Winter Weather</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-15 06:30:00</td>\n",
       "      <td>2015-01-15 06:30:00</td>\n",
       "      <td>2015-01-15 13:00:00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Winter Weather</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209935</th>\n",
       "      <td>394606</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-03-24 23:30:00</td>\n",
       "      <td>2023-03-24 22:46:00</td>\n",
       "      <td>2023-03-25 01:40:00</td>\n",
       "      <td>2.9</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56.0</td>\n",
       "      <td>High Wind</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209936</th>\n",
       "      <td>394607</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-03-24 23:45:00</td>\n",
       "      <td>2023-03-24 22:46:00</td>\n",
       "      <td>2023-03-25 01:40:00</td>\n",
       "      <td>2.9</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56.0</td>\n",
       "      <td>High Wind</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210102</th>\n",
       "      <td>394944</td>\n",
       "      <td>158.0</td>\n",
       "      <td>2023-09-04 13:00:00</td>\n",
       "      <td>2023-09-04 13:00:00</td>\n",
       "      <td>2023-09-04 14:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56.0</td>\n",
       "      <td>High Wind</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210196</th>\n",
       "      <td>395126</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-11-23 15:45:00</td>\n",
       "      <td>2023-11-23 15:05:00</td>\n",
       "      <td>2023-11-24 22:53:00</td>\n",
       "      <td>31.8</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Heavy Snow</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210197</th>\n",
       "      <td>395127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-11-23 16:00:00</td>\n",
       "      <td>2023-11-23 15:05:00</td>\n",
       "      <td>2023-11-24 22:53:00</td>\n",
       "      <td>31.8</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Heavy Snow</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32386 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  customers_out power_outage_datetime  \\\n",
       "6               27            1.0   2015-01-15 05:30:00   \n",
       "7               28            1.0   2015-01-15 05:45:00   \n",
       "8               29            1.0   2015-01-15 06:00:00   \n",
       "9               30            1.0   2015-01-15 06:15:00   \n",
       "10              31            1.0   2015-01-15 06:30:00   \n",
       "...            ...            ...                   ...   \n",
       "209935      394606            1.0   2023-03-24 23:30:00   \n",
       "209936      394607            2.0   2023-03-24 23:45:00   \n",
       "210102      394944          158.0   2023-09-04 13:00:00   \n",
       "210196      395126            1.0   2023-11-23 15:45:00   \n",
       "210197      395127            1.0   2023-11-23 16:00:00   \n",
       "\n",
       "       storm_start_datetime_est storm_end_datetime_est  duration_hours  \\\n",
       "6           2015-01-15 05:30:00    2015-01-15 10:00:00             4.5   \n",
       "7           2015-01-15 05:30:00    2015-01-15 10:00:00             4.5   \n",
       "8           2015-01-15 06:00:00    2015-01-15 10:30:00             4.5   \n",
       "9           2015-01-15 06:00:00    2015-01-15 10:30:00             4.5   \n",
       "10          2015-01-15 06:30:00    2015-01-15 13:00:00             6.5   \n",
       "...                         ...                    ...             ...   \n",
       "209935      2023-03-24 22:46:00    2023-03-25 01:40:00             2.9   \n",
       "209936      2023-03-24 22:46:00    2023-03-25 01:40:00             2.9   \n",
       "210102      2023-09-04 13:00:00    2023-09-04 14:00:00             1.0   \n",
       "210196      2023-11-23 15:05:00    2023-11-24 22:53:00            31.8   \n",
       "210197      2023-11-23 15:05:00    2023-11-24 22:53:00            31.8   \n",
       "\n",
       "          STATE  STATE_FIPS      EVENT_TYPE CZ_TYPE  ...  has_wind has_tree  \\\n",
       "6       ALABAMA         1.0  Winter Weather       Z  ...         0        0   \n",
       "7       ALABAMA         1.0  Winter Weather       Z  ...         0        0   \n",
       "8       ALABAMA         1.0  Winter Weather       Z  ...         0        0   \n",
       "9       ALABAMA         1.0  Winter Weather       Z  ...         0        0   \n",
       "10      ALABAMA         1.0  Winter Weather       Z  ...         0        0   \n",
       "...         ...         ...             ...     ...  ...       ...      ...   \n",
       "209935  WYOMING        56.0       High Wind       Z  ...         1        0   \n",
       "209936  WYOMING        56.0       High Wind       Z  ...         1        0   \n",
       "210102  WYOMING        56.0       High Wind       Z  ...         1        0   \n",
       "210196  WYOMING        56.0      Heavy Snow       Z  ...         0        0   \n",
       "210197  WYOMING        56.0      Heavy Snow       Z  ...         0        0   \n",
       "\n",
       "       has_power  has_damage  has_outage  has_broken  has_blown  \\\n",
       "6              0           0           0           0          0   \n",
       "7              0           0           0           0          0   \n",
       "8              0           0           0           0          0   \n",
       "9              0           0           0           0          0   \n",
       "10             0           0           0           0          0   \n",
       "...          ...         ...         ...         ...        ...   \n",
       "209935         0           0           0           0          0   \n",
       "209936         0           0           0           0          0   \n",
       "210102         0           0           0           0          0   \n",
       "210196         0           0           0           0          0   \n",
       "210197         0           0           0           0          0   \n",
       "\n",
       "        is_storm_lagged  predicted_storm severity_predicted  \n",
       "6                     1                1                  0  \n",
       "7                     1                1                  0  \n",
       "8                     1                1                  0  \n",
       "9                     1                1                  0  \n",
       "10                    1                1                  0  \n",
       "...                 ...              ...                ...  \n",
       "209935                1                1                  0  \n",
       "209936                1                1                  0  \n",
       "210102                1                1                  0  \n",
       "210196                1                1                  0  \n",
       "210197                1                1                  0  \n",
       "\n",
       "[32386 rows x 49 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:41.348516Z",
     "iopub.status.busy": "2025-04-27T05:59:41.348261Z",
     "iopub.status.idle": "2025-04-27T05:59:41.378172Z",
     "shell.execute_reply": "2025-04-27T05:59:41.377526Z",
     "shell.execute_reply.started": "2025-04-27T05:59:41.348500Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>customers_out</th>\n",
       "      <th>power_outage_datetime</th>\n",
       "      <th>storm_start_datetime_est</th>\n",
       "      <th>storm_end_datetime_est</th>\n",
       "      <th>duration_hours</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>CZ_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>has_wind</th>\n",
       "      <th>has_tree</th>\n",
       "      <th>has_power</th>\n",
       "      <th>has_damage</th>\n",
       "      <th>has_outage</th>\n",
       "      <th>has_broken</th>\n",
       "      <th>has_blown</th>\n",
       "      <th>is_storm_lagged</th>\n",
       "      <th>predicted_storm</th>\n",
       "      <th>severity_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-15 05:00:00</td>\n",
       "      <td>2015-01-15 05:00:00</td>\n",
       "      <td>2015-01-15 10:00:00</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Winter Weather</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-15 05:15:00</td>\n",
       "      <td>2015-01-15 05:00:00</td>\n",
       "      <td>2015-01-15 10:00:00</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Winter Weather</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-25 16:30:00</td>\n",
       "      <td>2015-01-25 16:30:00</td>\n",
       "      <td>2015-01-25 16:40:00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>53</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2015-02-20 19:00:00</td>\n",
       "      <td>2015-02-20 18:35:00</td>\n",
       "      <td>2015-02-21 03:15:00</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ice Storm</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>59</td>\n",
       "      <td>287.0</td>\n",
       "      <td>2015-02-25 10:00:00</td>\n",
       "      <td>2015-02-25 10:00:00</td>\n",
       "      <td>2015-02-25 18:30:00</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Heavy Snow</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210252</th>\n",
       "      <td>395231</td>\n",
       "      <td>519.0</td>\n",
       "      <td>2023-12-23 15:00:00</td>\n",
       "      <td>2023-12-23 15:00:00</td>\n",
       "      <td>2023-12-24 03:00:00</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Winter Weather</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210256</th>\n",
       "      <td>395239</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-12-25 18:00:00</td>\n",
       "      <td>2023-12-25 18:00:00</td>\n",
       "      <td>2023-12-26 16:00:00</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Winter Weather</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210257</th>\n",
       "      <td>395240</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-12-25 18:15:00</td>\n",
       "      <td>2023-12-25 18:00:00</td>\n",
       "      <td>2023-12-26 16:00:00</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Winter Weather</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210258</th>\n",
       "      <td>395241</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-12-25 18:30:00</td>\n",
       "      <td>2023-12-25 18:00:00</td>\n",
       "      <td>2023-12-26 16:00:00</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Winter Weather</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210259</th>\n",
       "      <td>395242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-12-25 18:45:00</td>\n",
       "      <td>2023-12-25 18:00:00</td>\n",
       "      <td>2023-12-26 16:00:00</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Winter Weather</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30439 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  customers_out power_outage_datetime  \\\n",
       "4               25            1.0   2015-01-15 05:00:00   \n",
       "5               26            1.0   2015-01-15 05:15:00   \n",
       "11              37            1.0   2015-01-25 16:30:00   \n",
       "22              53            3.0   2015-02-20 19:00:00   \n",
       "24              59          287.0   2015-02-25 10:00:00   \n",
       "...            ...            ...                   ...   \n",
       "210252      395231          519.0   2023-12-23 15:00:00   \n",
       "210256      395239            2.0   2023-12-25 18:00:00   \n",
       "210257      395240            2.0   2023-12-25 18:15:00   \n",
       "210258      395241            2.0   2023-12-25 18:30:00   \n",
       "210259      395242            2.0   2023-12-25 18:45:00   \n",
       "\n",
       "       storm_start_datetime_est storm_end_datetime_est  duration_hours  \\\n",
       "4           2015-01-15 05:00:00    2015-01-15 10:00:00        5.000000   \n",
       "5           2015-01-15 05:00:00    2015-01-15 10:00:00        5.000000   \n",
       "11          2015-01-25 16:30:00    2015-01-25 16:40:00        0.166667   \n",
       "22          2015-02-20 18:35:00    2015-02-21 03:15:00        8.666667   \n",
       "24          2015-02-25 10:00:00    2015-02-25 18:30:00        8.500000   \n",
       "...                         ...                    ...             ...   \n",
       "210252      2023-12-23 15:00:00    2023-12-24 03:00:00       12.000000   \n",
       "210256      2023-12-25 18:00:00    2023-12-26 16:00:00       22.000000   \n",
       "210257      2023-12-25 18:00:00    2023-12-26 16:00:00       22.000000   \n",
       "210258      2023-12-25 18:00:00    2023-12-26 16:00:00       22.000000   \n",
       "210259      2023-12-25 18:00:00    2023-12-26 16:00:00       22.000000   \n",
       "\n",
       "          STATE  STATE_FIPS         EVENT_TYPE CZ_TYPE  ...  has_wind  \\\n",
       "4       ALABAMA         1.0     Winter Weather       Z  ...         0   \n",
       "5       ALABAMA         1.0     Winter Weather       Z  ...         0   \n",
       "11      ALABAMA         1.0  Thunderstorm Wind       C  ...         1   \n",
       "22      ALABAMA         1.0          Ice Storm       Z  ...         0   \n",
       "24      ALABAMA         1.0         Heavy Snow       Z  ...         0   \n",
       "...         ...         ...                ...     ...  ...       ...   \n",
       "210252  WYOMING        56.0     Winter Weather       Z  ...         0   \n",
       "210256  WYOMING        56.0     Winter Weather       Z  ...         1   \n",
       "210257  WYOMING        56.0     Winter Weather       Z  ...         1   \n",
       "210258  WYOMING        56.0     Winter Weather       Z  ...         1   \n",
       "210259  WYOMING        56.0     Winter Weather       Z  ...         1   \n",
       "\n",
       "       has_tree has_power  has_damage  has_outage  has_broken  has_blown  \\\n",
       "4             0         0           0           0           0          0   \n",
       "5             0         0           0           0           0          0   \n",
       "11            1         0           0           0           0          0   \n",
       "22            0         0           0           0           0          0   \n",
       "24            0         0           0           0           0          0   \n",
       "...         ...       ...         ...         ...         ...        ...   \n",
       "210252        0         0           0           0           0          0   \n",
       "210256        0         0           0           0           0          0   \n",
       "210257        0         0           0           0           0          0   \n",
       "210258        0         0           0           0           0          0   \n",
       "210259        0         0           0           0           0          0   \n",
       "\n",
       "        is_storm_lagged  predicted_storm severity_predicted  \n",
       "4                     1                1                  1  \n",
       "5                     1                1                  1  \n",
       "11                    1                1                  1  \n",
       "22                    1                1                  1  \n",
       "24                    1                1                  1  \n",
       "...                 ...              ...                ...  \n",
       "210252                1                1                  1  \n",
       "210256                1                1                  1  \n",
       "210257                1                1                  1  \n",
       "210258                1                1                  1  \n",
       "210259                1                1                  1  \n",
       "\n",
       "[30439 rows x 49 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:41.379124Z",
     "iopub.status.busy": "2025-04-27T05:59:41.378927Z",
     "iopub.status.idle": "2025-04-27T05:59:41.409980Z",
     "shell.execute_reply": "2025-04-27T05:59:41.409344Z",
     "shell.execute_reply.started": "2025-04-27T05:59:41.379107Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>customers_out</th>\n",
       "      <th>power_outage_datetime</th>\n",
       "      <th>storm_start_datetime_est</th>\n",
       "      <th>storm_end_datetime_est</th>\n",
       "      <th>duration_hours</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>CZ_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>has_wind</th>\n",
       "      <th>has_tree</th>\n",
       "      <th>has_power</th>\n",
       "      <th>has_damage</th>\n",
       "      <th>has_outage</th>\n",
       "      <th>has_broken</th>\n",
       "      <th>has_blown</th>\n",
       "      <th>is_storm_lagged</th>\n",
       "      <th>predicted_storm</th>\n",
       "      <th>severity_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>54</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2015-02-20 20:45:00</td>\n",
       "      <td>2015-02-20 20:40:00</td>\n",
       "      <td>2015-02-21 03:00:00</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ice Storm</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>72</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015-02-25 14:00:00</td>\n",
       "      <td>2015-02-25 14:00:00</td>\n",
       "      <td>2015-02-25 20:30:00</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Heavy Snow</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>73</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015-02-25 14:15:00</td>\n",
       "      <td>2015-02-25 14:00:00</td>\n",
       "      <td>2015-02-25 20:30:00</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Heavy Snow</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>74</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2015-02-25 14:30:00</td>\n",
       "      <td>2015-02-25 14:30:00</td>\n",
       "      <td>2015-02-25 21:30:00</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Heavy Snow</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>75</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2015-02-25 14:45:00</td>\n",
       "      <td>2015-02-25 14:30:00</td>\n",
       "      <td>2015-02-25 21:30:00</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Heavy Snow</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210262</th>\n",
       "      <td>395245</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2023-12-25 19:30:00</td>\n",
       "      <td>2023-12-25 19:00:00</td>\n",
       "      <td>2023-12-27 02:00:00</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Heavy Snow</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210263</th>\n",
       "      <td>395246</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2023-12-25 19:45:00</td>\n",
       "      <td>2023-12-25 19:00:00</td>\n",
       "      <td>2023-12-27 02:00:00</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Heavy Snow</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210264</th>\n",
       "      <td>395247</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023-12-25 20:00:00</td>\n",
       "      <td>2023-12-25 20:00:00</td>\n",
       "      <td>2023-12-26 00:46:00</td>\n",
       "      <td>4.766667</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56.0</td>\n",
       "      <td>High Wind</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210265</th>\n",
       "      <td>395248</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2023-12-25 20:15:00</td>\n",
       "      <td>2023-12-25 20:00:00</td>\n",
       "      <td>2023-12-26 00:46:00</td>\n",
       "      <td>4.766667</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56.0</td>\n",
       "      <td>High Wind</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210269</th>\n",
       "      <td>395252</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2023-12-25 21:30:00</td>\n",
       "      <td>2023-12-25 21:30:00</td>\n",
       "      <td>2023-12-26 16:45:00</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Heavy Snow</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32205 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  customers_out power_outage_datetime  \\\n",
       "23              54           79.0   2015-02-20 20:45:00   \n",
       "37              72            4.0   2015-02-25 14:00:00   \n",
       "38              73            4.0   2015-02-25 14:15:00   \n",
       "39              74            3.0   2015-02-25 14:30:00   \n",
       "40              75           16.0   2015-02-25 14:45:00   \n",
       "...            ...            ...                   ...   \n",
       "210262      395245            3.0   2023-12-25 19:30:00   \n",
       "210263      395246            4.0   2023-12-25 19:45:00   \n",
       "210264      395247            5.0   2023-12-25 20:00:00   \n",
       "210265      395248            4.0   2023-12-25 20:15:00   \n",
       "210269      395252            3.0   2023-12-25 21:30:00   \n",
       "\n",
       "       storm_start_datetime_est storm_end_datetime_est  duration_hours  \\\n",
       "23          2015-02-20 20:40:00    2015-02-21 03:00:00        6.333333   \n",
       "37          2015-02-25 14:00:00    2015-02-25 20:30:00        6.500000   \n",
       "38          2015-02-25 14:00:00    2015-02-25 20:30:00        6.500000   \n",
       "39          2015-02-25 14:30:00    2015-02-25 21:30:00        7.000000   \n",
       "40          2015-02-25 14:30:00    2015-02-25 21:30:00        7.000000   \n",
       "...                         ...                    ...             ...   \n",
       "210262      2023-12-25 19:00:00    2023-12-27 02:00:00       31.000000   \n",
       "210263      2023-12-25 19:00:00    2023-12-27 02:00:00       31.000000   \n",
       "210264      2023-12-25 20:00:00    2023-12-26 00:46:00        4.766667   \n",
       "210265      2023-12-25 20:00:00    2023-12-26 00:46:00        4.766667   \n",
       "210269      2023-12-25 21:30:00    2023-12-26 16:45:00       19.250000   \n",
       "\n",
       "          STATE  STATE_FIPS  EVENT_TYPE CZ_TYPE  ...  has_wind has_tree  \\\n",
       "23      ALABAMA         1.0   Ice Storm       Z  ...         0        1   \n",
       "37      ALABAMA         1.0  Heavy Snow       Z  ...         0        0   \n",
       "38      ALABAMA         1.0  Heavy Snow       Z  ...         0        0   \n",
       "39      ALABAMA         1.0  Heavy Snow       Z  ...         0        0   \n",
       "40      ALABAMA         1.0  Heavy Snow       Z  ...         0        0   \n",
       "...         ...         ...         ...     ...  ...       ...      ...   \n",
       "210262  WYOMING        56.0  Heavy Snow       Z  ...         1        0   \n",
       "210263  WYOMING        56.0  Heavy Snow       Z  ...         1        0   \n",
       "210264  WYOMING        56.0   High Wind       Z  ...         1        0   \n",
       "210265  WYOMING        56.0   High Wind       Z  ...         1        0   \n",
       "210269  WYOMING        56.0  Heavy Snow       Z  ...         1        0   \n",
       "\n",
       "       has_power  has_damage  has_outage  has_broken  has_blown  \\\n",
       "23             0           0           0           0          0   \n",
       "37             0           0           0           0          0   \n",
       "38             0           0           0           0          0   \n",
       "39             0           0           0           0          0   \n",
       "40             0           0           0           0          0   \n",
       "...          ...         ...         ...         ...        ...   \n",
       "210262         0           0           0           0          0   \n",
       "210263         0           0           0           0          0   \n",
       "210264         0           0           0           0          0   \n",
       "210265         0           0           0           0          0   \n",
       "210269         0           0           0           0          0   \n",
       "\n",
       "        is_storm_lagged  predicted_storm severity_predicted  \n",
       "23                    1                1                  2  \n",
       "37                    1                1                  2  \n",
       "38                    1                1                  2  \n",
       "39                    1                1                  2  \n",
       "40                    1                1                  2  \n",
       "...                 ...              ...                ...  \n",
       "210262                1                1                  2  \n",
       "210263                1                1                  2  \n",
       "210264                1                1                  2  \n",
       "210265                1                1                  2  \n",
       "210269                1                1                  2  \n",
       "\n",
       "[32205 rows x 49 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:41.410876Z",
     "iopub.status.busy": "2025-04-27T05:59:41.410642Z",
     "iopub.status.idle": "2025-04-27T05:59:45.371708Z",
     "shell.execute_reply": "2025-04-27T05:59:45.370899Z",
     "shell.execute_reply.started": "2025-04-27T05:59:41.410860Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/1656639219.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['is_outage'] = (df['customers_out'] > 0).astype(int)\n",
      "/tmp/ipykernel_31/1656639219.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['is_outage'] = (df['customers_out'] > 0).astype(int)\n",
      "/tmp/ipykernel_31/1656639219.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['is_outage'] = (df['customers_out'] > 0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import lightgbm as lgb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Define outage features (common for all models)\n",
    "outage_features = [\n",
    "    'tmin', 'tmax', 'tavg', 'ppt',\n",
    "    'has_tornado', 'has_hail', 'has_flood', 'has_wind', 'has_tree',\n",
    "    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'duration_hours',\n",
    "    'desc_word_count', 'desc_char_count'\n",
    "]\n",
    "\n",
    "# Derive is_outage target (assuming customers_out > 0 indicates an outage)\n",
    "for df in [df_low, df_medium, df_high]:\n",
    "    df['is_outage'] = (df['customers_out'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling the imbalanced data\n",
    "\n",
    "After Going through the data, we found that the data is heavily imbalanced (our approach), where we had around 100 instances of No outage being true and 30000 of Outage being true . The problem was that there were a lot of instances where there was no storm, but an outage was reported. We didn't address this issue at the time, so to solve it we took all the non-storm rows and randomly assigned each of them to either of Low, Medium or High severity classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:45.373157Z",
     "iopub.status.busy": "2025-04-27T05:59:45.372451Z",
     "iopub.status.idle": "2025-04-27T05:59:45.380245Z",
     "shell.execute_reply": "2025-04-27T05:59:45.379275Z",
     "shell.execute_reply.started": "2025-04-27T05:59:45.373138Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storm_no_outage_count_l = len(df_low[(df_low['predicted_storm'] == 1) & (df_low['customers_out'] == 0)])\n",
    "storm_no_outage_count_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:45.381640Z",
     "iopub.status.busy": "2025-04-27T05:59:45.381290Z",
     "iopub.status.idle": "2025-04-27T05:59:45.404552Z",
     "shell.execute_reply": "2025-04-27T05:59:45.403839Z",
     "shell.execute_reply.started": "2025-04-27T05:59:45.381614Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storm_no_outage_count_m = len(df_medium[(df_medium['predicted_storm'] == 1) & (df_medium['customers_out'] == 0)])\n",
    "storm_no_outage_count_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:45.405857Z",
     "iopub.status.busy": "2025-04-27T05:59:45.405495Z",
     "iopub.status.idle": "2025-04-27T05:59:45.417638Z",
     "shell.execute_reply": "2025-04-27T05:59:45.416852Z",
     "shell.execute_reply.started": "2025-04-27T05:59:45.405834Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storm_no_outage_count_h = len(df_high[(df_high['predicted_storm'] == 1) & (df_high['customers_out'] == 0)])\n",
    "storm_no_outage_count_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:45.418763Z",
     "iopub.status.busy": "2025-04-27T05:59:45.418492Z",
     "iopub.status.idle": "2025-04-27T05:59:45.433881Z",
     "shell.execute_reply": "2025-04-27T05:59:45.433117Z",
     "shell.execute_reply.started": "2025-04-27T05:59:45.418744Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_storm_no_outage_count = len(storm_df_with_predictions[(storm_df_with_predictions['predicted_storm'] == 0) & (storm_df_with_predictions['customers_out'] == 0)])\n",
    "non_storm_no_outage_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:45.435003Z",
     "iopub.status.busy": "2025-04-27T05:59:45.434749Z",
     "iopub.status.idle": "2025-04-27T05:59:45.503340Z",
     "shell.execute_reply": "2025-04-27T05:59:45.502716Z",
     "shell.execute_reply.started": "2025-04-27T05:59:45.434981Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103896"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_storm_count = len(storm_df_with_predictions[storm_df_with_predictions['predicted_storm'] == 0])\n",
    "non_storm_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:45.504220Z",
     "iopub.status.busy": "2025-04-27T05:59:45.503995Z",
     "iopub.status.idle": "2025-04-27T05:59:45.585869Z",
     "shell.execute_reply": "2025-04-27T05:59:45.585130Z",
     "shell.execute_reply.started": "2025-04-27T05:59:45.504204Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Extract non-storm rows from storm_df_with_predictions\n",
    "non_storm_data = storm_df_with_predictions[storm_df_with_predictions['predicted_storm'] == 0].copy()\n",
    "non_storm_data['is_outage'] = 0  # No outage for non-storm events\n",
    "non_storm_data['severity_predicted'] = 10  # Placeholder for non-storm rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:45.586769Z",
     "iopub.status.busy": "2025-04-27T05:59:45.586556Z",
     "iopub.status.idle": "2025-04-27T05:59:45.733339Z",
     "shell.execute_reply": "2025-04-27T05:59:45.732516Z",
     "shell.execute_reply.started": "2025-04-27T05:59:45.586753Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Randomly split non-storm rows across the three DataFrames\n",
    "non_storm_split = np.array_split(non_storm_data.sample(frac=1, random_state=42), 3)\n",
    "non_storm_low, non_storm_medium, non_storm_high = non_storm_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:45.734389Z",
     "iopub.status.busy": "2025-04-27T05:59:45.734192Z",
     "iopub.status.idle": "2025-04-27T05:59:45.799369Z",
     "shell.execute_reply": "2025-04-27T05:59:45.798699Z",
     "shell.execute_reply.started": "2025-04-27T05:59:45.734373Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Augment DataFrames with non-storm rows\n",
    "df_low = pd.concat([df_low, non_storm_low], ignore_index=True)\n",
    "df_medium = pd.concat([df_medium, non_storm_medium], ignore_index=True)\n",
    "df_high = pd.concat([df_high, non_storm_high], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-27T05:57:13.348412Z",
     "iopub.status.idle": "2025-04-27T05:57:13.348708Z",
     "shell.execute_reply": "2025-04-27T05:57:13.348542Z",
     "shell.execute_reply.started": "2025-04-27T05:57:13.348526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:45.800434Z",
     "iopub.status.busy": "2025-04-27T05:59:45.800178Z",
     "iopub.status.idle": "2025-04-27T05:59:46.511899Z",
     "shell.execute_reply": "2025-04-27T05:59:46.511000Z",
     "shell.execute_reply.started": "2025-04-27T05:59:45.800412Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 25787, number of negative: 27827\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2089\n",
      "[LightGBM] [Info] Number of data points in the train set: 53614, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.480975 -> initscore=-0.076136\n",
      "[LightGBM] [Info] Start training from score -0.076136\n",
      "LightGBM (Low Severity) Metrics:\n",
      "Accuracy: 0.9043569083855566\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91      6957\n",
      "           1       0.88      0.93      0.90      6447\n",
      "\n",
      "    accuracy                           0.90     13404\n",
      "   macro avg       0.90      0.91      0.90     13404\n",
      "weighted avg       0.91      0.90      0.90     13404\n",
      "\n",
      "Confusion Matrix:\n",
      " [[6125  832]\n",
      " [ 450 5997]]\n"
     ]
    }
   ],
   "source": [
    "# 1. LightGBM for Low Severity\n",
    "if not df_low.empty:\n",
    "    X_low = df_low[outage_features]\n",
    "    y_low = df_low['is_outage']\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train_low, X_test_low, y_train_low, y_test_low = train_test_split(\n",
    "        X_low, y_low, test_size=0.2, stratify=y_low, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler_low = StandardScaler()\n",
    "    X_train_low_scaled = scaler_low.fit_transform(X_train_low)\n",
    "    X_test_low_scaled = scaler_low.transform(X_test_low)\n",
    "    \n",
    "    # Train LightGBM\n",
    "    lgb_model = lgb.LGBMClassifier(n_estimators=100, random_state=42)\n",
    "    lgb_model.fit(X_train_low_scaled, y_train_low)\n",
    "    \n",
    "    # Predict on test set\n",
    "    low_predictions = lgb_model.predict(X_test_low_scaled)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"LightGBM (Low Severity) Metrics:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test_low, low_predictions))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test_low, low_predictions))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_low, low_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:46.513184Z",
     "iopub.status.busy": "2025-04-27T05:59:46.512825Z",
     "iopub.status.idle": "2025-04-27T05:59:47.657377Z",
     "shell.execute_reply": "2025-04-27T05:59:47.656771Z",
     "shell.execute_reply.started": "2025-04-27T05:59:46.513160Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost (Low Severity) Metrics:\n",
      "Accuracy: 0.8816025067144136\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88      6957\n",
      "           1       0.85      0.92      0.88      6447\n",
      "\n",
      "    accuracy                           0.88     13404\n",
      "   macro avg       0.88      0.88      0.88     13404\n",
      "weighted avg       0.88      0.88      0.88     13404\n",
      "\n",
      "Confusion Matrix:\n",
      " [[5907 1050]\n",
      " [ 537 5910]]\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 1. CatBoost for Low Severity\n",
    "if not df_low.empty:\n",
    "    X_low = df_low[outage_features]\n",
    "    y_low = df_low['is_outage']\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train_low, X_test_low, y_train_low, y_test_low = train_test_split(\n",
    "        X_low, y_low, test_size=0.2, stratify=y_low, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler_low = StandardScaler()\n",
    "    X_train_low_scaled = scaler_low.fit_transform(X_train_low)\n",
    "    X_test_low_scaled = scaler_low.transform(X_test_low)\n",
    "    \n",
    "    # Train CatBoost\n",
    "    cat_model = CatBoostClassifier(\n",
    "        iterations=100,\n",
    "        learning_rate=0.1,\n",
    "        depth=6,\n",
    "        auto_class_weights='Balanced',\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "    cat_model.fit(X_train_low_scaled, y_train_low)\n",
    "    \n",
    "    # Predict on test set\n",
    "    low_predictions = cat_model.predict(X_test_low_scaled)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"CatBoost (Low Severity) Metrics:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test_low, low_predictions))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test_low, low_predictions))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_low, low_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:47.658412Z",
     "iopub.status.busy": "2025-04-27T05:59:47.658090Z",
     "iopub.status.idle": "2025-04-27T05:59:50.500677Z",
     "shell.execute_reply": "2025-04-27T05:59:50.499962Z",
     "shell.execute_reply.started": "2025-04-27T05:59:47.658394Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest (Low Severity) Metrics:\n",
      "Accuracy: 0.9530737093404954\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95      6957\n",
      "           1       0.95      0.96      0.95      6447\n",
      "\n",
      "    accuracy                           0.95     13404\n",
      "   macro avg       0.95      0.95      0.95     13404\n",
      "weighted avg       0.95      0.95      0.95     13404\n",
      "\n",
      "Confusion Matrix:\n",
      " [[6612  345]\n",
      " [ 284 6163]]\n"
     ]
    }
   ],
   "source": [
    "# 2. Random Forest for Low Severity\n",
    "if not df_medium.empty:\n",
    "    X_medium = df_low[outage_features]\n",
    "    y_medium = df_low['is_outage']\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train_medium, X_test_medium, y_train_medium, y_test_medium = train_test_split(\n",
    "        X_medium, y_medium, test_size=0.2, stratify=y_medium, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler_medium = StandardScaler()\n",
    "    X_train_medium_scaled = scaler_medium.fit_transform(X_train_medium)\n",
    "    X_test_medium_scaled = scaler_medium.transform(X_test_medium)\n",
    "    \n",
    "    # Train Random Forest\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf_model.fit(X_train_medium_scaled, y_train_medium)\n",
    "    \n",
    "    # Predict on test set\n",
    "    medium_predictions = rf_model.predict(X_test_medium_scaled)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\nRandom Forest (Low Severity) Metrics:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test_medium, medium_predictions))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test_medium, medium_predictions))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_medium, medium_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEDIUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:50.501786Z",
     "iopub.status.busy": "2025-04-27T05:59:50.501501Z",
     "iopub.status.idle": "2025-04-27T05:59:53.280724Z",
     "shell.execute_reply": "2025-04-27T05:59:53.280031Z",
     "shell.execute_reply.started": "2025-04-27T05:59:50.501769Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest (Medium Severity) Metrics:\n",
      "Accuracy: 0.9278524779101037\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      6943\n",
      "           1       0.91      0.94      0.92      6072\n",
      "\n",
      "    accuracy                           0.93     13015\n",
      "   macro avg       0.93      0.93      0.93     13015\n",
      "weighted avg       0.93      0.93      0.93     13015\n",
      "\n",
      "Confusion Matrix:\n",
      " [[6372  571]\n",
      " [ 368 5704]]\n"
     ]
    }
   ],
   "source": [
    "# 2. Random Forest for Medium Severity\n",
    "if not df_medium.empty:\n",
    "    X_medium = df_medium[outage_features]\n",
    "    y_medium = df_medium['is_outage']\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train_medium, X_test_medium, y_train_medium, y_test_medium = train_test_split(\n",
    "        X_medium, y_medium, test_size=0.2, stratify=y_medium, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler_medium = StandardScaler()\n",
    "    X_train_medium_scaled = scaler_medium.fit_transform(X_train_medium)\n",
    "    X_test_medium_scaled = scaler_medium.transform(X_test_medium)\n",
    "    \n",
    "    # Train Random Forest\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf_model.fit(X_train_medium_scaled, y_train_medium)\n",
    "    \n",
    "    # Predict on test set\n",
    "    medium_predictions = rf_model.predict(X_test_medium_scaled)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\nRandom Forest (Medium Severity) Metrics:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test_medium, medium_predictions))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test_medium, medium_predictions))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_medium, medium_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:59:53.281840Z",
     "iopub.status.busy": "2025-04-27T05:59:53.281582Z",
     "iopub.status.idle": "2025-04-27T06:01:04.718181Z",
     "shell.execute_reply": "2025-04-27T06:01:04.717505Z",
     "shell.execute_reply.started": "2025-04-27T05:59:53.281821Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745733609.703601      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "I0000 00:00:1745733613.430093     148 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\n",
      "LSTM (High Severity) Metrics:\n",
      "Accuracy: 0.5205633380777587\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.68      6936\n",
      "           1       0.70      0.00      0.01      6413\n",
      "\n",
      "    accuracy                           0.52     13349\n",
      "   macro avg       0.61      0.50      0.35     13349\n",
      "weighted avg       0.61      0.52      0.36     13349\n",
      "\n",
      "Confusion Matrix:\n",
      " [[6926   10]\n",
      " [6390   23]]\n"
     ]
    }
   ],
   "source": [
    "# 3. LSTM for High Severity\n",
    "if not df_high.empty:\n",
    "    # Function to create sequences for LSTM\n",
    "    def create_sequences(data, seq_length=3):\n",
    "        sequences = []\n",
    "        targets = []\n",
    "        indices = []\n",
    "        for state in data['STATE_FIPS'].unique():\n",
    "            state_data = data[data['STATE_FIPS'] == state].sort_values('power_outage_datetime')\n",
    "            X_state = state_data[outage_features].values\n",
    "            y_state = state_data['is_outage'].values\n",
    "            state_indices = state_data.index\n",
    "            for i in range(len(X_state) - seq_length + 1):\n",
    "                sequences.append(X_state[i:i + seq_length])\n",
    "                targets.append(y_state[i + seq_length - 1])\n",
    "                indices.append(state_indices[i + seq_length - 1])\n",
    "        return np.array(sequences), np.array(targets), indices\n",
    "    \n",
    "    # Prepare sequences\n",
    "    seq_length = 3\n",
    "    X_high, y_high, high_indices = create_sequences(df_high, seq_length)\n",
    "    \n",
    "    # Train-test split for sequences\n",
    "    X_train_high, X_test_high, y_train_high, y_test_high, train_indices, test_indices = train_test_split(\n",
    "        X_high, y_high, high_indices, test_size=0.2, stratify=y_high, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler_high = StandardScaler()\n",
    "    X_train_high_scaled = np.array([scaler_high.fit_transform(seq) for seq in X_train_high])\n",
    "    X_test_high_scaled = np.array([scaler_high.transform(seq) for seq in X_test_high])\n",
    "    \n",
    "    # Define LSTM model\n",
    "    lstm_model = Sequential([\n",
    "        LSTM(50, input_shape=(seq_length, len(outage_features)), return_sequences=False),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    lstm_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    \n",
    "    # Train LSTM\n",
    "    lstm_model.fit(X_train_high_scaled, y_train_high, epochs=10, batch_size=32, verbose=0)\n",
    "    \n",
    "    # Predict on test set\n",
    "    high_predictions = (lstm_model.predict(X_test_high_scaled) > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\nLSTM (High Severity) Metrics:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test_high, high_predictions))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test_high, high_predictions))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_high, high_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T06:01:04.721230Z",
     "iopub.status.busy": "2025-04-27T06:01:04.720788Z",
     "iopub.status.idle": "2025-04-27T06:01:04.724720Z",
     "shell.execute_reply": "2025-04-27T06:01:04.724051Z",
     "shell.execute_reply.started": "2025-04-27T06:01:04.721212Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T06:01:04.726032Z",
     "iopub.status.busy": "2025-04-27T06:01:04.725534Z",
     "iopub.status.idle": "2025-04-27T06:01:31.826813Z",
     "shell.execute_reply": "2025-04-27T06:01:31.826046Z",
     "shell.execute_reply.started": "2025-04-27T06:01:04.726008Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745733666.603021     147 service.cc:148] XLA service 0x7ded7c010100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745733666.603598     147 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1745733668.179604     147 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "Feedforward Neural Network (High Severity) Metrics:\n",
      "Accuracy: 0.8706612806702573\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87      6944\n",
      "           1       0.85      0.89      0.87      6424\n",
      "\n",
      "    accuracy                           0.87     13368\n",
      "   macro avg       0.87      0.87      0.87     13368\n",
      "weighted avg       0.87      0.87      0.87     13368\n",
      "\n",
      "Confusion Matrix:\n",
      " [[5919 1025]\n",
      " [ 704 5720]]\n"
     ]
    }
   ],
   "source": [
    "# 3. Feedforward Neural Network for High Severity\n",
    "if not df_high.empty:\n",
    "    X_high = df_high[outage_features]\n",
    "    y_high = df_high['is_outage']\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train_high, X_test_high, y_train_high, y_test_high = train_test_split(\n",
    "        X_high, y_high, test_size=0.2, stratify=y_high, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler_high = StandardScaler()\n",
    "    X_train_high_scaled = scaler_high.fit_transform(X_train_high)\n",
    "    X_test_high_scaled = scaler_high.transform(X_test_high)\n",
    "    \n",
    "    # Define FNN model\n",
    "    fnn_model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(len(outage_features),)),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    fnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train model\n",
    "    fnn_model.fit(\n",
    "        X_train_high_scaled, y_train_high,\n",
    "        epochs=20,\n",
    "        batch_size=64,\n",
    "        validation_split=0.2,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Predict on test set\n",
    "    high_predictions = (fnn_model.predict(X_test_high_scaled) > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\nFeedforward Neural Network (High Severity) Metrics:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test_high, high_predictions))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test_high, high_predictions))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_high, high_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T06:01:31.828373Z",
     "iopub.status.busy": "2025-04-27T06:01:31.827698Z",
     "iopub.status.idle": "2025-04-27T06:01:34.730562Z",
     "shell.execute_reply": "2025-04-27T06:01:34.729808Z",
     "shell.execute_reply.started": "2025-04-27T06:01:31.828348Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest (High Severity) Metrics:\n",
      "Accuracy: 0.9367145421903053\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      6944\n",
      "           1       0.92      0.95      0.94      6424\n",
      "\n",
      "    accuracy                           0.94     13368\n",
      "   macro avg       0.94      0.94      0.94     13368\n",
      "weighted avg       0.94      0.94      0.94     13368\n",
      "\n",
      "Confusion Matrix:\n",
      " [[6425  519]\n",
      " [ 327 6097]]\n"
     ]
    }
   ],
   "source": [
    "# 2. Random Forest for High Severity\n",
    "if not df_high.empty:\n",
    "    X_medium = df_high[outage_features]\n",
    "    y_medium = df_high['is_outage']\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train_medium, X_test_medium, y_train_medium, y_test_medium = train_test_split(\n",
    "        X_medium, y_medium, test_size=0.2, stratify=y_medium, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler_medium = StandardScaler()\n",
    "    X_train_medium_scaled = scaler_medium.fit_transform(X_train_medium)\n",
    "    X_test_medium_scaled = scaler_medium.transform(X_test_medium)\n",
    "    \n",
    "    # Train Random Forest\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf_model.fit(X_train_medium_scaled, y_train_medium)\n",
    "    \n",
    "    # Predict on test set\n",
    "    medium_predictions = rf_model.predict(X_test_medium_scaled)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\nRandom Forest (High Severity) Metrics:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test_medium, medium_predictions))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test_medium, medium_predictions))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_medium, medium_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T00:08:20.475091Z",
     "iopub.status.busy": "2025-04-27T00:08:20.474278Z",
     "iopub.status.idle": "2025-04-27T00:27:50.874692Z",
     "shell.execute_reply": "2025-04-27T00:27:50.873824Z",
     "shell.execute_reply.started": "2025-04-27T00:08:20.475073Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  15.8s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  19.6s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 2.3min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   7.4s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   7.8s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   7.8s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  52.5s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  52.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuned Random Forest (Low Severity) Metrics:\n",
      "Accuracy: 0.937013764213046\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      6944\n",
      "           1       0.92      0.95      0.94      6424\n",
      "\n",
      "    accuracy                           0.94     13368\n",
      "   macro avg       0.94      0.94      0.94     13368\n",
      "weighted avg       0.94      0.94      0.94     13368\n",
      "\n",
      "Confusion Matrix:\n",
      " [[6428  516]\n",
      " [ 326 6098]]\n",
      "Best Parameters:\n",
      " {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 50, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Parameter grid\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf_estimator = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# RandomizedSearchCV\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    estimator=rf_estimator,\n",
    "    param_distributions=rf_param_grid,\n",
    "    n_iter=30,  # number of random combinations to try\n",
    "    scoring='f1',  # or 'accuracy' if you prefer\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit to training data\n",
    "rf_random_search.fit(X_train_medium_scaled, y_train_medium)\n",
    "\n",
    "# Best model\n",
    "best_rf_model = rf_random_search.best_estimator_\n",
    "\n",
    "# Predict and evaluate\n",
    "best_rf_predictions = best_rf_model.predict(X_test_medium_scaled)\n",
    "\n",
    "print(\"\\nTuned Random Forest (Low Severity) Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_medium, best_rf_predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_medium, best_rf_predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_medium, best_rf_predictions))\n",
    "\n",
    "# Show best parameters\n",
    "print(\"Best Parameters:\\n\", rf_random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T00:27:50.879916Z",
     "iopub.status.busy": "2025-04-27T00:27:50.879573Z",
     "iopub.status.idle": "2025-04-27T00:47:20.834726Z",
     "shell.execute_reply": "2025-04-27T00:47:20.833859Z",
     "shell.execute_reply.started": "2025-04-27T00:27:50.879891Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  16.3s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  19.7s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  36.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  35.8s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  37.3s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  14.1s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  52.1s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  52.5s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  27.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  27.0s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  53.9s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  14.9s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  15.3s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  15.3s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  10.2s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  10.4s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  10.5s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time= 2.2min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  10.8s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time= 2.4min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  40.5s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  55.2s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  38.7s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=None, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time= 3.2min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  17.0s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  19.6s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 2.3min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  14.2s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  53.7s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  51.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuned Random Forest (Medium Severity) Metrics:\n",
      "Accuracy: 0.937013764213046\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      6944\n",
      "           1       0.92      0.95      0.94      6424\n",
      "\n",
      "    accuracy                           0.94     13368\n",
      "   macro avg       0.94      0.94      0.94     13368\n",
      "weighted avg       0.94      0.94      0.94     13368\n",
      "\n",
      "Confusion Matrix:\n",
      " [[6428  516]\n",
      " [ 326 6098]]\n",
      "Best Parameters:\n",
      " {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 50, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Parameter grid for Random Forest\n",
    "rf_param_grid_medium = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf_estimator_medium = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# RandomizedSearchCV setup\n",
    "rf_random_search_medium = RandomizedSearchCV(\n",
    "    estimator=rf_estimator_medium,\n",
    "    param_distributions=rf_param_grid_medium,\n",
    "    n_iter=30,  # Number of random combinations to try\n",
    "    scoring='f1',  # You can switch to 'accuracy' if you prefer\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV to training data\n",
    "rf_random_search_medium.fit(X_train_medium_scaled, y_train_medium)\n",
    "\n",
    "# Best Random Forest model\n",
    "best_rf_model_medium = rf_random_search_medium.best_estimator_\n",
    "\n",
    "# Predict and evaluate\n",
    "best_medium_predictions = best_rf_model_medium.predict(X_test_medium_scaled)\n",
    "\n",
    "print(\"\\nTuned Random Forest (Medium Severity) Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_medium, best_medium_predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_medium, best_medium_predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_medium, best_medium_predictions))\n",
    "\n",
    "# Best parameters found\n",
    "print(\"Best Parameters:\\n\", rf_random_search_medium.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T06:01:43.135948Z",
     "iopub.status.busy": "2025-04-27T06:01:43.135724Z",
     "iopub.status.idle": "2025-04-27T06:01:43.208063Z",
     "shell.execute_reply": "2025-04-27T06:01:43.207035Z",
     "shell.execute_reply.started": "2025-04-27T06:01:43.135932Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scikeras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/3057160032.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscikeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scikeras'"
     ]
    }
   ],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to create model (for KerasClassifier)\n",
    "def create_fnn_model(hidden_layer_sizes=(64, 32, 16), dropout_rate=0.3, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layer_sizes[0], activation='relu', input_shape=(len(outage_features),)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(hidden_layer_sizes[1], activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(hidden_layer_sizes[2], activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Wrap model\n",
    "fnn_wrapper = KerasClassifier(\n",
    "    model=create_fnn_model,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Define parameter grid\n",
    "fnn_param_grid = {\n",
    "    'model__hidden_layer_sizes': [(128, 64, 32), (64, 32, 16), (32, 16, 8)],\n",
    "    'model__dropout_rate': [0.2, 0.3, 0.5],\n",
    "    'model__learning_rate': [1e-2, 1e-3, 1e-4],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [30, 50, 70]\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV\n",
    "fnn_random_search = RandomizedSearchCV(\n",
    "    estimator=fnn_wrapper,\n",
    "    param_distributions=fnn_param_grid,\n",
    "    n_iter=20,  # number of random combinations\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "fnn_random_search.fit(X_train_high_scaled, y_train_high)\n",
    "\n",
    "# Best model\n",
    "best_fnn_model = fnn_random_search.best_estimator_\n",
    "\n",
    "# Predict and evaluate\n",
    "high_predictions_best = (best_fnn_model.predict(X_test_high_scaled) > 0.5).astype(int).flatten()\n",
    "\n",
    "print(\"\\nTuned Feedforward Neural Network (High Severity) Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_high, high_predictions_best))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_high, high_predictions_best))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_high, high_predictions_best))\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\\n\", fnn_random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T06:01:34.731744Z",
     "iopub.status.busy": "2025-04-27T06:01:34.731430Z",
     "iopub.status.idle": "2025-04-27T06:01:43.134973Z",
     "shell.execute_reply": "2025-04-27T06:01:43.134339Z",
     "shell.execute_reply.started": "2025-04-27T06:01:34.731719Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Random Forest (Low Severity) Metrics:\n",
      "Accuracy: 0.9532975231274247\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95      6957\n",
      "           1       0.95      0.96      0.95      6447\n",
      "\n",
      "    accuracy                           0.95     13404\n",
      "   macro avg       0.95      0.95      0.95     13404\n",
      "weighted avg       0.95      0.95      0.95     13404\n",
      "\n",
      "Confusion Matrix:\n",
      " [[6611  346]\n",
      " [ 280 6167]]\n",
      "\n",
      "Model saved as 'rf_low_severity_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib  # For saving model\n",
    "\n",
    "# 1. Prepare data\n",
    "if not df_low.empty:\n",
    "    X_low = df_low[outage_features]\n",
    "    y_low = df_low['is_outage']\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train_low, X_test_low, y_train_low, y_test_low = train_test_split(\n",
    "        X_low, y_low, test_size=0.2, stratify=y_low, random_state=42\n",
    "    )\n",
    "\n",
    "    # 2. Train Random Forest (no scaling needed!)\n",
    "    rf_final_model = RandomForestClassifier(\n",
    "        n_estimators=300,    # Slightly more trees for stability\n",
    "        max_depth=None,      # Let trees grow fully unless needed\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        bootstrap=True\n",
    "    )\n",
    "    rf_final_model.fit(X_train_low, y_train_low)\n",
    "\n",
    "    # 3. Evaluate\n",
    "    low_predictions = rf_final_model.predict(X_test_low)\n",
    "    \n",
    "    print(\"\\nFinal Random Forest (Low Severity) Metrics:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test_low, low_predictions))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test_low, low_predictions))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_low, low_predictions))\n",
    "\n",
    "    # 4. Save model\n",
    "    joblib.dump(rf_final_model, 'rf_low_severity_model.pkl')\n",
    "    print(\"\\nModel saved as 'rf_low_severity_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:54:22.359199Z",
     "iopub.status.busy": "2025-04-27T05:54:22.358661Z",
     "iopub.status.idle": "2025-04-27T05:54:29.586298Z",
     "shell.execute_reply": "2025-04-27T05:54:29.585411Z",
     "shell.execute_reply.started": "2025-04-27T05:54:22.359173Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikeras\n",
      "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikeras) (3.5.0)\n",
      "Collecting scikit-learn>=1.4.2 (from scikeras)\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (14.0.0)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (3.12.1)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.14.0)\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (24.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->keras>=3.2.0->scikeras) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->keras>=3.2.0->scikeras) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->keras>=3.2.0->scikeras) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->keras>=3.2.0->scikeras) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->keras>=3.2.0->scikeras) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->keras>=3.2.0->scikeras) (2.4.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras>=3.2.0->scikeras) (4.13.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->keras>=3.2.0->scikeras) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->keras>=3.2.0->scikeras) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->keras>=3.2.0->scikeras) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->keras>=3.2.0->scikeras) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->keras>=3.2.0->scikeras) (2024.2.0)\n",
      "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
      "Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scikit-learn, scikeras\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.1 which is incompatible.\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed scikeras-0.13.0 scikit-learn-1.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikeras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7232568,
     "sourceId": 11531217,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
